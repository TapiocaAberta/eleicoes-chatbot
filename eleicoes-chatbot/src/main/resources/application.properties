quarkus.web-bundler.dependencies.node-modules=node_modules

# Infinispan configurations
quarkus.infinispan-client.hosts=localhost:11222
quarkus.infinispan-client.username=admin
quarkus.infinispan-client.password=secret

# Configure the Infinispan vectors:
quarkus.langchain4j.infinispan.dimension=384
quarkus.langchain4j.infinispan.cache-name=eleicoes-chatbot

#quarkus.langchain4j.log-requests=true
#quarkus.langchain4j.log-responses=true

#quarkus.langchain4j.chat-model.provider=openai
quarkus.langchain4j.chat-model.provider=ollama
quarkus.langchain4j.embedding-model.provider=dev.langchain4j.model.embedding.onnx.bgesmallenq.BgeSmallEnQuantizedEmbeddingModel

# Configure the OpenAI service to use instruct lab:
#quarkus.langchain4j.openai.chat-model.model-name=merlinite-7b-lab-Q4_K_M
#quarkus.langchain4j.openai.base-url=http://localhost:8000/v1
#quarkus.langchain4j.openai.chat-model.temperature=0.3
#quarkus.langchain4j.openai.timeout=600s

#Configure Ollama to use llama 3.1
quarkus.langchain4j.ollama.timeout=600s
quarkus.langchain4j.ollama.chat-model.temperature=0.3
quarkus.langchain4j.ollama.chat-model.top-k=30
quarkus.langchain4j.ollama.chat-model.log-requests=true
quarkus.langchain4j.ollama.chat-model.log-responses=true